
## Tensorflow

1. Save and Load model by meta graph

### save
// build graph ...
saver=tf.train.Saver()
//run seession
saver.save(sess,"/tmp/model.ckpt");

### restore
//create a session 
   sess = tf.Session()
    saver=tf.train.import_meta_graph("/tmp/model.ckpt.meta")
    save_path=saver.restore(sess,"/tmp/model.ckpt");


2. Save and load mobel by freeze

https://gist.githubusercontent.com/morgangiraud/249505f540a5e53a48b0c1a869d370bf/raw/6cb0b4d497925517316a92f935ce5dccb6aafd17/medium-tffreeze-1.py
https://github.com/abdasgupta/tensorflow-serving-ppc64le/blob/flowers-export/tensorflow_serving/example/inception_export.py

The more offically method is:
(1) Get the graph definition by:
   tf.train.write_graph(sess.graph.as_graph_def(),"./models/save","graph.pb");
   
(2) Get the weight data by save checkpoint 
     saver=tf.train.Saver()
     saver.save(sess,"./models/save");

(3) Using the freeze_graph.py inside tensorflow/python/tools
     --input_graph  <saved_graph_pb>
     --input_checkpoint <saved_checkpoint_dir>+prefix
     --output_graph <file_to_save>
     --output_node_names <node1,node2>
     
3.  Generate libtensorflow.so for other language to use
bazel build //tensorflow:libtensorflow.so

4. A simple C++ sample program

https://medium.com/jim-fleming/loading-a-tensorflow-graph-with-the-c-api-4caaff88463f


5. libtensorflow distribution package


Yes, if you have it working acceptably with copying, I'd say you should continue using that. Premature optimization is the root of all evil ;)

That said, I realize you probably need to build with bazel build -c opt //tensorflow/tools/lib_package:libtensorflow and look at bazel-bin/tensorflow/tools/lib_package/libtensorflow.tar.gz (which includes the header and .so you need). Linking that should expose the C API.

6. C API Sample

TF_Status* s = TF_NewStatus();
TF_Graph* graph = TF_NewGraph();

const char* graph_def_data; // <-- your serialized GraphDef here
TF_Buffer graph_def = {graph_def_data, strlen(graph_def_data), nullptr};

// Import `graph_def` into `graph`
TF_ImportGraphDefOptions* import_opts = TF_NewImportGraphDefOptions();
TF_ImportGraphDefOptionsSetPrefix(import_opts, "import");
TF_GraphImportGraphDef(graph, &graph_def, import_opts, s);
assert(TF_GetCode(s) == TF_OK);

// Setup graph inputs
std::vector<TF_Output> inputs;
std::vector<TF_Tensor*> input_values;
// Add the placeholders you would like to feed, e.g.:
TF_Operation* placeholder = TF_GraphOperationByName(graph, "import/my_placeholder");
inputs.push_back({placeholder, 0});
TF_Tensor* tensor = TF_NewTensor(/*...*/);
input_values.push_back(tensor);

// Setup graph outputs
std::vector<TF_Output> outputs;
// Add the node outputs you would like to fetch, e.g.:
TF_Operation* output_op = TF_GraphOperationByName(graph, "import/my_output");
outputs.push_back({output_op, 0});
std::vector<TF_Tensor*> output_values(outputs.size(), nullptr);

// Run `graph`
TF_SessionOptions* sess_opts = TF_NewSessionOptions();
TF_Session* session = TF_NewSession(graph, sess_opts, s);
assert(TF_GetCode(s) == TF_OK);
TF_SessionRun(session, nullptr,
              &inputs[0], &input_values[0], inputs.size(),
              &outputs[0], &output_values[0], outputs.size(),
              nullptr, 0, nullptr, s);

void* output_data = TF_TensorData(output_values[0]);
assert(TF_GetCode(s) == TF_OK);

// If you have a more complicated workflow, I suggest making scoped wrapper
// classes that call these in their destructors
for (int i = 0; i < inputs.size(); ++i) TF_DeleteTensor(input_values[i]);
for (int i = 0; i < outputs.size(); ++i) TF_DeleteTensor(output_values[i]);
TF_CloseSession(session, s);
TF_DeleteSession(session, s);
TF_DeleteSessionOptions(sess_opts);
TF_DeleteImportGraphDefOptions(import_opts);
TF_DeleteGraph(graph);
TF_DeleteStatus(s);
 
----------------------------------
Urgly code to reuse a pre-allocated buffer in C++...
const int64_t tensorDims[4] = {1,inputheight,inputwidth,3};
int *imNumPt = new int(1);
TF_Tensor* tftensor = TF_NewTensor(TF_DataType::TF_UINT8, tensorDims, 4,
                           cameraImg.data, inputheight * inputwidth * 3,
                           NULL, imNumPt);
Tensor inputImg = tensorflow::TensorCApi::MakeTensor(tftensor->dtype, tftensor->shape, tftensor->buffer);






